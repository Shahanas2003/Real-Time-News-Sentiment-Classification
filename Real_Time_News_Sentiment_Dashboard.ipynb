{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlIiETUaaYR3IzQZKNWiak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahanas2003/Real-Time-News-Sentiment-Classification/blob/main/Real_Time_News_Sentiment_Dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# -----------------------------\n",
        "# NewsData.io API Configuration\n",
        "# -----------------------------\n",
        "API_KEY = \"pub_7c7f72f816dc47c28a889f0c0a5b371f\"\n",
        "BASE_URL = \"https://newsdata.io/api/1/news\"\n",
        "\n",
        "# Allowed categories\n",
        "VALID_CATEGORIES = [\"business\", \"entertainment\", \"environment\", \"food\", \"health\",\n",
        "                    \"politics\", \"science\", \"sports\", \"technology\", \"top\"]\n",
        "\n",
        "def fetch_news(api_key, language=\"en\", category=\"top\"):\n",
        "    if category not in VALID_CATEGORIES:\n",
        "        raise ValueError(f\"Invalid category '{category}'. Valid options: {VALID_CATEGORIES}\")\n",
        "\n",
        "    params = {\n",
        "        \"apikey\": api_key,\n",
        "        \"language\": language,\n",
        "        \"category\": category\n",
        "    }\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"results\", [])\n",
        "    else:\n",
        "        print(f\"Error fetching news: {response.status_code}, {response.text}\")\n",
        "        return []\n",
        "\n",
        "# -----------------------------\n",
        "# Fetch global top news\n",
        "# -----------------------------\n",
        "articles = fetch_news(API_KEY, category=\"top\")\n",
        "\n",
        "# -----------------------------\n",
        "# Display fetched news\n",
        "# -----------------------------\n",
        "if articles:\n",
        "    for idx, article in enumerate(articles, start=1):\n",
        "        print(f\"{idx}. {article.get('title')}\")\n",
        "        print(f\"   Description: {article.get('description')}\")\n",
        "        print(f\"   Link: {article.get('link')}\")\n",
        "        print(f\"   Published: {article.get('pubDate')}\")\n",
        "        print(f\"   Source: {article.get('source_id')}\")\n",
        "        print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"No articles fetched.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu2a9kT7MEqW",
        "outputId": "4b24510d-3fdc-4c03-ba7e-eb06665bb73d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Malta Guinness Partners Iri Ji Festival in Lagos\n",
            "   Description: Malta Guinness has announced its partnership with this year’s Iri Ji Festival, scheduled for Sunday, September 28, at FHA Ground, Festac. The event will bring together families and community members\n",
            "   Link: https://www.thisdaylive.com/2025/09/27/malta-guinness-partners-iri-ji-festival-in-lagos/\n",
            "   Published: 2025-09-27 21:07:00\n",
            "   Source: thisdaylive\n",
            "--------------------------------------------------------------------------------\n",
            "2. Could the United Nations be dying?\n",
            "   Description: The UN tried to reach for the heavens. But now we must wonder whether it has sunk to the pits...\n",
            "   Link: https://nation.africa/kenya/blogs-opinion/opinion/could-the-united-nations-be-dying--5208482\n",
            "   Published: 2025-09-27 21:07:00\n",
            "   Source: nation\n",
            "--------------------------------------------------------------------------------\n",
            "3. Cyclist dies in crash with vehicle north of Longmont\n",
            "   Description: The cyclist was pronounced dead at the scene. The 50-year-old man driving the Honda was not injured and remained at the crash site.\n",
            "   Link: https://www.dailycamera.com/2025/09/27/cyclist-dies-in-crash-with-vehicle-north-of-longmont/\n",
            "   Published: 2025-09-27 21:06:58\n",
            "   Source: dailycamera\n",
            "--------------------------------------------------------------------------------\n",
            "4. Cyclist dies in crash with vehicle north of Longmont\n",
            "   Description: The cyclist was pronounced dead at the scene. The 50-year-old man driving the Honda was not injured and remained at the crash site.\n",
            "   Link: https://www.timescall.com/2025/09/27/cyclist-dies-in-crash-with-vehicle-north-of-longmont/\n",
            "   Published: 2025-09-27 21:06:58\n",
            "   Source: timescall\n",
            "--------------------------------------------------------------------------------\n",
            "5. Motorcyclist charged with reckless operation following high-speed highway pursuit: North Olmsted Police Blotter\n",
            "   Description: North Olmsted police charged a motorcyclist with reckless operation following a high-speed chase during which the pursuing cruiser’s speed reached 130 mph.An officer at about 12:43 a.m. on Sept. 14 spotted two motorcycles rapidly approaching him from behind on I-480 near Stearns Road. As the first motorcycle passed the officer’s cruiser, he attempted to catch up to it for a traffic stop.\n",
            "   Link: https://www.cleveland.com/community/2025/09/motorcyclist-charged-with-reckless-operation-following-high-speed-highway-pursuit-north-olmsted-police-blotter.html\n",
            "   Published: 2025-09-27 21:06:53\n",
            "   Source: cleveland\n",
            "--------------------------------------------------------------------------------\n",
            "6. Suspect charged with attempted murder against child in eastern Ontario: OPP - CTV News\n",
            "   Description: Suspect charged with attempted murder against child in eastern Ontario: OPP CTV NewsMan charged with attempted murder, sexual assault of a child: OPP CBC26-year-old arrested for attempted murder of child: OPP SooToday.com\n",
            "   Link: https://news.google.com/rss/articles/CBMiswFBVV95cUxNWFJDNmFYU193Q0o5Qks2SXR0UG1pN2paLVdydGV1aFZlTDJ2RTVzUnFBc25HbS02aThyaEJxTDJJMlN3TWV0LWw2NTMweUZoblk0THdCUjdENGFxSE9UaDFtc0c4N3Yzd0lKQWxJMDczeU9aejl5U1pHbXJPXzlHS1hJSm5LWm1BMnlKc0hyamdoUTVzdVlaZDMtSTVGRG1hM09zUHZzQTdtSXYtN1dDb2NDOA?oc=5\n",
            "   Published: 2025-09-27 21:06:51\n",
            "   Source: google\n",
            "--------------------------------------------------------------------------------\n",
            "7. Suspect charged with attempted murder against child in eastern Ontario: OPP - CP24\n",
            "   Description: Suspect charged with attempted murder against child in eastern Ontario: OPP CP24View Full Coverage on Google News\n",
            "   Link: https://news.google.com/rss/articles/CBMiuwFBVV95cUxNUUpJa3VvUWNnaUwxNjVWRUxfLXBRQTBpMDJmWU9OS3hpTmhLa1loYTdld1JPRjNRd3hFa0NZT1RzSnNCdWFLLWR4WFE1VUYtdTM0U1d3Mi02LUJJa2JaOTc3M3VFdmZia3dMX3dqOXJhWm1UM2tfSDF0TTJOQ01aVll2N1Y0dWFrSm40RDBzSHVoUTYzd1VzZHhYcE52Q21IUHpfaEZnSGJKLWdDRTV5SGxGcGppMjBMX01V?oc=5\n",
            "   Published: 2025-09-27 21:06:51\n",
            "   Source: google\n",
            "--------------------------------------------------------------------------------\n",
            "8. Delegation of clerics meets DIG\n",
            "   Description: Deputy Inspector General of Police (DIGP) Shaheed Benazirabad Range, Faisal Bashir Memon, held an important meeting with a delegation from the Shia Ulema Council at his office. During the meeting, the delegation apprised DIG of various issues and matters concerning the community. DIG attentively listened to their grievances and issued immediate instructions for their resolution. [...]\n",
            "   Link: https://dailytimes.com.pk/1375244/delegation-of-clerics-meets-dig/\n",
            "   Published: 2025-09-27 21:06:42\n",
            "   Source: dailytimes_pk\n",
            "--------------------------------------------------------------------------------\n",
            "9. Myanmar Art Centre (Yangon) set for international-standard upgrade\n",
            "   Description: According to the Ministry of Religious Affairs and Culture, the Myanmar Art Centre (Yangon) will be transformed into an international [...]\n",
            "   Link: https://www.gnlm.com.mm/myanmar-art-centre-yangon-set-for-international-standard-upgrade/\n",
            "   Published: 2025-09-27 21:06:41\n",
            "   Source: gnlm_mm\n",
            "--------------------------------------------------------------------------------\n",
            "10. Floating Voters and Even Some NDC Members Are Asking for Kennedy Agyapong – Charles Bissue\n",
            "   Description: According to a report by GhanaWeb, Charles Bissue, the Director of Operations for Kennedy Agyapong’s campaign team, has emphasized that the politician’s appeal in Ghanaian politics stems from his personal character rather than a regional stronghold. Speaking on Channel One TV, Bissue noted that Agyapong, a hopeful for the New Patriotic Party (NPP) flagbearer position, [...]The post Floating Voters and Even Some NDC Members Are Asking for Kennedy Agyapong – Charles Bissue appeared first on Ghanamma.com.\n",
            "   Link: https://www.ghanamma.com/2025/09/27/floating-voters-and-even-some-ndc-members-are-asking-for-kennedy-agyapong-charles-bissue/\n",
            "   Published: 2025-09-27 21:06:39\n",
            "   Source: ghanamma\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Step 2: News Sentiment Classification\n",
        "# -----------------------------\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, regexp_replace\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder.appName(\"NewsSentimentClassification\").getOrCreate()\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Labeled Training Data\n",
        "# 0 = Negative, 1 = Positive\n",
        "# -----------------------------\n",
        "data = [\n",
        "    (\"Stock markets crash amid economic fears\", 0),\n",
        "    (\"Local community celebrates festival with joy\", 1),\n",
        "    (\"Earthquake kills hundreds in city\", 0),\n",
        "    (\"New vaccine brings hope to millions\", 1),\n",
        "    (\"Government faces backlash over corruption scandal\", 0),\n",
        "    (\"Breakthrough in clean energy technology announced\", 1)\n",
        "]\n",
        "\n",
        "columns = [\"title\", \"label\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Build Pipeline\n",
        "# -----------------------------\n",
        "# Clean text for training data\n",
        "df_clean = df.withColumn(\"clean_title\", lower(regexp_replace(col(\"title\"), \"[^a-zA-Z0-9\\\\s]\", \"\")))\n",
        "\n",
        "# Pipeline stages\n",
        "tokenizer = Tokenizer(inputCol=\"clean_title\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Train the model\n",
        "# -----------------------------\n",
        "model = pipeline.fit(df_clean)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Test Predictions\n",
        "# -----------------------------\n",
        "test_data = [\n",
        "    (\"The economy shows signs of recovery\",),\n",
        "    (\"Massive floods destroy farmlands\",),\n",
        "    (\"Breakthrough in cancer treatment gives hope\",)\n",
        "]\n",
        "test_df = spark.createDataFrame(test_data, [\"title\"])\n",
        "\n",
        "# Apply the same cleaning step to the test data\n",
        "test_df_clean = test_df.withColumn(\"clean_title\", lower(regexp_replace(col(\"title\"), \"[^a-zA-Z0-9\\\\s]\", \"\")))\n",
        "\n",
        "predictions = model.transform(test_df_clean)\n",
        "predictions.select(\"title\", \"prediction\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2CwtFZ2nFGb",
        "outputId": "b6ca5abd-ace2-4743-a252-eb794d2fd96d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+----------+\n",
            "|title                                      |prediction|\n",
            "+-------------------------------------------+----------+\n",
            "|The economy shows signs of recovery        |0.0       |\n",
            "|Massive floods destroy farmlands           |0.0       |\n",
            "|Breakthrough in cancer treatment gives hope|1.0       |\n",
            "+-------------------------------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "SAVE_DIR = \"/content/news_stream_folder\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "def save_articles(articles):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = os.path.join(SAVE_DIR, f\"news_{ts}.json\")\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for article in articles:\n",
        "            json.dump({\"title\": article.get(\"title\", \"\")}, f)\n",
        "            f.write(\"\\n\")\n",
        "    print(f\"Saved {len(articles)} articles → {filename}\")\n"
      ],
      "metadata": {
        "id": "jyTNhgVAnixB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StringType\n",
        "\n",
        "# Define schema for streaming JSON files\n",
        "schema = StructType().add(\"title\", StringType(), True)\n",
        "\n",
        "# Read stream\n",
        "news_stream = spark.readStream.schema(schema).json(SAVE_DIR)\n"
      ],
      "metadata": {
        "id": "mSo_4FCYntNi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower, regexp_replace\n",
        "\n",
        "# Apply the same cleaning step to the news stream\n",
        "news_stream_clean = news_stream.withColumn(\"clean_title\", lower(regexp_replace(col(\"title\"), \"[^a-zA-Z0-9\\\\s]\", \"\")))\n",
        "\n",
        "# The trained 'model' from Step 2\n",
        "predictions_stream = model.transform(news_stream_clean).select(\"title\", \"prediction\")"
      ],
      "metadata": {
        "id": "A68mbOVqnu-T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output to console for debugging\n",
        "\n",
        "# Stop any existing query with the same name\n",
        "for q in spark.streams.active:\n",
        "    if q.name == \"news_predictions\":\n",
        "        q.stop()\n",
        "        print(f\"Stopped existing query: {q.name}\")\n",
        "\n",
        "query = predictions_stream.writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"news_predictions\") \\\n",
        "    .start()\n",
        "\n",
        "# Keep the stream running for a limited time for this example\n",
        "# In a real application, you might want a different termination strategy\n",
        "query.awaitTermination(timeout=60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzUHSU8Yn2Hk",
        "outputId": "d790a312-6690-436d-acb8-66ff5b47c2c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped existing query: news_predictions\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq1QGZPgpPKs",
        "outputId": "b42899ea-dd17-4488-c954-5eb2e7449e3f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, regexp_replace\n",
        "from pyspark.sql.types import StructType, StringType\n",
        "from pyspark.ml import PipelineModel\n",
        "from streamlit_autorefresh import st_autorefresh\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Initialize Spark and load model\n",
        "# -----------------------------\n",
        "@st.experimental_singleton\n",
        "def init_spark():\n",
        "    spark = SparkSession.builder.appName(\"NewsSentimentDashboard\").getOrCreate()\n",
        "    model = PipelineModel.load(\"/content/news_sentiment_model\")  # update path if needed\n",
        "    return spark, model\n",
        "\n",
        "spark, model = init_spark()\n",
        "\n",
        "# -----------------------------\n",
        "# 2. NewsData.io API\n",
        "# -----------------------------\n",
        "API_KEY = \"pub_7c7f72f816dc47c28a889f0c0a5b371f\"\n",
        "BASE_URL = \"https://newsdata.io/api/1/news\"\n",
        "SAVE_DIR = \"news_stream_folder\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "VALID_CATEGORIES = [\"business\",\"entertainment\",\"environment\",\"food\",\"health\",\n",
        "                    \"politics\",\"science\",\"sports\",\"technology\",\"top\"]\n",
        "\n",
        "def fetch_news(category=\"top\"):\n",
        "    params = {\"apikey\": API_KEY, \"language\":\"en\", \"category\":category}\n",
        "    r = requests.get(BASE_URL, params=params)\n",
        "    if r.status_code == 200:\n",
        "        return r.json().get(\"results\", [])\n",
        "    return []\n",
        "\n",
        "def save_articles(articles):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = os.path.join(SAVE_DIR, f\"news_{ts}.json\")\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for article in articles:\n",
        "            json.dump({\"title\": article.get(\"title\",\"\")}, f)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Spark Structured Streaming\n",
        "# -----------------------------\n",
        "schema = StructType().add(\"title\", StringType(), True)\n",
        "news_stream = spark.readStream.schema(schema).json(SAVE_DIR)\n",
        "predictions_stream = model.transform(news_stream).select(\"title\", \"prediction\")\n",
        "\n",
        "# Memory sink for dashboard\n",
        "query = predictions_stream.writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"news_predictions\") \\\n",
        "    .start()\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Streamlit Dashboard\n",
        "# -----------------------------\n",
        "st.title(\"Real-Time News Sentiment Dashboard\")\n",
        "\n",
        "category = st.selectbox(\"Select News Category:\", VALID_CATEGORIES)\n",
        "if st.button(\"Fetch Latest News\"):\n",
        "    articles = fetch_news(category)\n",
        "    if articles:\n",
        "        save_articles(articles)\n",
        "        st.success(f\"Fetched and saved {len(articles)} articles!\")\n",
        "    else:\n",
        "        st.warning(\"No articles fetched.\")\n",
        "\n",
        "# Auto-refresh every 5 seconds\n",
        "st_autorefresh(interval=5000, limit=None, key=\"news_refresh\")\n",
        "\n",
        "# Function to read memory table\n",
        "def get_latest_predictions():\n",
        "    try:\n",
        "        sdf = spark.sql(\"SELECT * FROM news_predictions\")\n",
        "        return sdf.toPandas()\n",
        "    except:\n",
        "        return pd.DataFrame(columns=[\"title\", \"prediction\"])\n",
        "\n",
        "df = get_latest_predictions()\n",
        "if not df.empty:\n",
        "    df[\"Sentiment\"] = df[\"prediction\"].map({0:\"Negative\", 1:\"Positive\"})\n",
        "    st.bar_chart(df[\"Sentiment\"].value_counts())\n",
        "    st.dataframe(df[[\"title\",\"Sentiment\"]].tail(20))\n",
        "else:\n",
        "    st.write(\"No news processed yet.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8YJNAB7rb7R",
        "outputId": "b797e53b-b239-46b4-9161-58d345383594"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    }
  ]
}